---
title: 'NodeJS Quickstart'
description: 'Start collecting data from your NodeJS (Express) project'
---

<Info>
  **Prerequisite** Please see [here](/api-key-setup) to get and set your API Key environment variable.
</Info>

Install the Lytix NPM package

<CodeGroup>

```bash npm
npm i @lytix/client
```

```bash yarn
yarn add @lytix/client
```

</CodeGroup>

## Integration

### Express Integration

Lytix provides an out of the box middleware that you can use to collect data from your NodeJS (Express) project.

To get started, simply add the middleware to your Express app.

```ts 
import { LytixRequestWrapper } from "@lytix/client";

....
const app = express();
...

/**
 * Pass the logger in as the 4th argument here
 * @note The 4th argument is a boolean that can be set to true to collect metrics 
 * related to your server
 */
app.use((req, res, next) => {
  return LytixRequestWrapper(req, res, next, false);
});

```
<Info>
Note: If you enable request metrics, data will be published with the `requestDuration` metric name
</Info>


### Manual Integration 

You can always wrap your entrypoint to get access to all of Lytix log tracing features (for example if you are running a cron job and have a main entrypoint)

```ts
import { LLogger } from "@lytix/client";


const logger = new LLogger("mainEntrypoint");

const main = async () => {
  logger.info(`Log from the main process`);
  await someBackgroundProcess();
};

/**
 * All we need to do is wrap our entrypoint and everything will
 * be accessable
 */
logger.runInAsyncContext(main);
```

## Error Capturing

#### Error Class

You can now just replace all your `throw new Error` calls with `throw new LError`. For example: 

```ts
...
app.get("/test", async (req, res) => {
  const logger = new LLogger('testRoute');
  /**
   * Lets pretend an error happend
   */
  try {
    logger.info("Some process is starting");
    throw new LError("An unexpeted error", { env: "prod" });
  } catch (err) {
    logger.error("crazy unexpeted error with this user: 123", err);
    res.sendStatus(500);
    return;
  }

  /**
   * Magically if we ended here, we'd reply with a 200
   */
  res.send("Hello World");
});
...
```

The error, along with the last 20 log lines will automatically get pushed to the lytix platform [here](https://lab.lytix.co/home/errors)

![title](/images/node-quickstart/LErrorExample.png)

#### Error Increment

You can also send an error along with related logs without throwing an error by using the `increment` method. 

```ts
import { LErrorIncrement, LLogger } from "@lytix/client";

/**
 * An example background process
 */
const backgroundProcess = async () => {
  const logger = new LLogger("backgroundProcessExample", { userId: "123" });
  try {
    logger.info("Background process started for user!");
    throw new Error("Unexpected error!");
  } catch (err) {
    /**
     * Just increment to get the logs as well as the error
     */
    logger.error(`Unexpected error happened`, err);
    LErrorIncrement("Unexpected error");
  }
};
```

#### Examples

To see all examples please check the Github repo [here](https://github.com/Lytix-Labs/lytix-js/tree/master/src/examples)

## LLM Model Input Output Collection

Lytix supports automatically collecting the input and output of LLM models. To do this you can use the following

```ts
import { MetricCollector } from "@lytix/client";

await MetricCollector.captureModelIO({
  modelName: "testModelName",
  modelInput: "Some user input",
  modelOutput: "Some model output",
  metricMetadata: {
    /**
     * Optional extra data
     */
    env: "prod",
  }
);
```

Lytix will automatically process the input and output of the LLM model and push the metrics to the Lytix platform. You can see your model metrics in the Lytix platform [here](https://lytix.co/home/llm/).

### LLM Model Trace Collection

Lytix also supports capturing trace information (e.g. duration) for the LLM model. To do this you can use the following

```ts
import { MetricCollector } from "@lytix/client";

const response = await MetricCollector.captureModelTrace({
  modelName: "testModelName",
  modelInput: "Some user input",
  generateModelOutput: async () => {
    const openai = new OpenAI();
    ...
    /**
     * This callback is expecting the model output to be returned
     */
    return response;
  }
});
```

You'll now see the model duration trace in the Lytix platform [here](https://lab.lytix.co/home/).

![title](/images/node-quickstart/llm-trace.png)

## Manual Metric Collection

You always have the option to manually push metrics to the Lytix platform with custom names and metadata. 

The following example pushes a metric to the Lytix platform with the name `testMetic` and the value `1` along with the `env: prod` metadata. 

```ts
import { MetricCollector } from "@lytix/client";

await MetricCollector.increment("testMetic", 1, { env: "prod" });
```

You then have access to that on the Lytix platform and can filter on any of the metadata passed.

![title](/images/node-quickstart/testMetricExample.png)